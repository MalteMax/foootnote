{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e7599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, requests, gzip, urllib.request, time, zipfile, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c67318",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd03a41",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58de83",
   "metadata": {},
   "source": [
    "read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10db664",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir('/Users/maltemax/Desktop/files_sec') if f.endswith('zip')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf758f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(unzip_location, file, 'tag.tsv'), 'r') as f:\n",
    "#     lis = [line.split('\\t') for line in f]\n",
    "# d = pd.DataFrame(lis)\n",
    "# tag = pd.DataFrame(lis)\n",
    "# tag.columns = tag.loc[0].tolist()\n",
    "# tag = tag.drop(0)\n",
    "# tag.replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "031a0d9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aed7e4b7094a07becf8edb3636a0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 480899: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:13: DtypeWarning: Columns (35,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sub = pd.read_csv(os.path.join(unzip_location, file, 'sub.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 530291: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 91798: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 602232: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:13: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sub = pd.read_csv(os.path.join(unzip_location, file, 'sub.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 374579: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:13: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sub = pd.read_csv(os.path.join(unzip_location, file, 'sub.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:13: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sub = pd.read_csv(os.path.join(unzip_location, file, 'sub.tsv'), sep = '\\t')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 838521: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 754776: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:13: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sub = pd.read_csv(os.path.join(unzip_location, file, 'sub.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:18: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 100862: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 69252: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 582206: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/1342275349.py:24: ParserWarning: Skipping line 607590: expected 9 fields, saw 10\n",
      "\n",
      "  tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n"
     ]
    }
   ],
   "source": [
    "files_location = '/Users/maltemax/Desktop/files_sec'\n",
    "unzip_location = '/Users/maltemax/Desktop/temp_unzip'\n",
    "if not os.path.exists(unzip_location):\n",
    "    os.makedirs(unzip_location)\n",
    "\n",
    "collect = []\n",
    "\n",
    "for file in tqdm(files):\n",
    "    with zipfile.ZipFile(os.path.join(files_location, file), 'r') as zip_file:\n",
    "        zip_file.extractall(os.path.join(unzip_location, file))\n",
    "    \n",
    "    # sub has all submissions for the given period\n",
    "    sub = pd.read_csv(os.path.join(unzip_location, file, 'sub.tsv'), sep = '\\t')\n",
    "    sub = sub.loc[sub['form'] == '10-K']\n",
    "    sub = sub[['adsh', 'cik', 'name', 'sic', 'period', 'fy', 'filed', 'instance']]\n",
    "    \n",
    "    # num has numerical values, one row for each tagged item\n",
    "    num = pd.read_csv(os.path.join(unzip_location, file, 'num.tsv'), sep = '\\t')\n",
    "    num = num.loc[num['tag'].notna()]\n",
    "    num['tag'] = num['tag'].str.lower()\n",
    "    num = num.loc[num['tag'].str.contains('deferredtaxasset', flags = re.IGNORECASE)]\n",
    "    \n",
    "    # tag has tag information (official description, custom, etc.)\n",
    "    tag = pd.read_csv(os.path.join(unzip_location, file, 'tag.tsv'), sep = '\\t', on_bad_lines = 'warn')\n",
    "    tag = tag.loc[tag['tag'].notna()]\n",
    "    tag['tag'] = tag['tag'].str.lower()\n",
    "    tag = tag.drop_duplicates('tag')\n",
    "    tag = tag[['tag', 'custom', 'tlabel', 'doc']]\n",
    "    \n",
    "    # taking sub as the basis so that firms with no tags are retained\n",
    "    # add num and tag information\n",
    "    sub = sub.merge(right = num, how = 'left', on = 'adsh')\n",
    "    sub = sub.merge(right = tag, how = 'left', on = 'tag')\n",
    "    \n",
    "    collect.append(sub)\n",
    "    \n",
    "    # delete the unzipped directory\n",
    "    shutil.rmtree(os.path.join(unzip_location, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5d4a529",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/0rcsgf6524x_7ns1b5_sllfm0000gn/T/ipykernel_18369/3824935784.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(collect, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(collect, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e822c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url_instance'] = ('https://www.sec.gov/Archives/edgar/data/' +\n",
    "                      df['cik'].astype(str) + '/' +\n",
    "                      df['adsh'].str.replace('-', '') + '/' +\n",
    "                      df['instance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9423b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(os.getcwd(), '3_pipeline', '1_intermediate', 'dta_data_raw.tsv'),\n",
    "          sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd6189",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcf0538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(), '3_pipeline', '1_intermediate', 'dta_data_raw.tsv'),\n",
    "                 sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7aa9cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag'].value_counts().to_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "794fc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['deferredtaxassetsgross',\n",
    "        'deferredtaxassetsgrossnoncurrent',\n",
    "        'deferredtaxassetsgrosscurrent',\n",
    "        'deferredtaxassetgross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03ace39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['tag'].isin(tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "19edb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['period'] = pd.to_datetime(df['period'], format = '%Y%m%d')\n",
    "df['ddate'] = pd.to_datetime(df['ddate'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "546b7a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fiscal\n",
    "df['fyear'] = np.where(df['period'].dt.month <= 5,\n",
    "                       df['period'].dt.year - 1,\n",
    "                       df['period'].dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5b29b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['fyear'].isin(range(2012, 2024 + 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "38010074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['value'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "88319d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48327"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['adsh'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "10ad519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to entries that are about the current fiscal year\n",
    "df = df.loc[(df['period'].dt.year == df['ddate'].dt.year) &\n",
    "            (df['period'].dt.month == df['ddate'].dt.month)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3ee311e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059052</th>\n",
       "      <td>deferredtaxassetsgross</td>\n",
       "      <td>1002000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059059</th>\n",
       "      <td>deferredtaxassetsgross</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059065</th>\n",
       "      <td>deferredtaxassetsgross</td>\n",
       "      <td>227000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tag      value\n",
       "1059052  deferredtaxassetsgross  1002000.0\n",
       "1059059  deferredtaxassetsgross    25000.0\n",
       "1059065  deferredtaxassetsgross   227000.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['adsh'] == '0000353184-13-000009', ['tag', 'value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3ae02",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8b2a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace INF (shown as 32767) by zero; INF means that it shows exact amounts, no rounding\n",
    "# which is equal to dcml of 0\n",
    "# some documents in the VA data also appear to have -32768, which I also set to 0\n",
    "df['dcml'] = np.where((df['dcml'] == 32767) | (df['dcml'] == -32768), 0, df['dcml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9f025c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are only very few cases with a dcml of > 0 (what do they mean?)\n",
    "df = df.loc[df['dcml'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80e40f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_decimal'] = df.groupby('adsh')['dcml'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7410cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round all amounts to lowest level of precision used in report\n",
    "df['dta_min_accuracy'] = np.round(df['value'] / (10 ** abs(df['min_decimal'])), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4aceb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = ['cik', 'fyear', 'dta_min_accuracy'], keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a97cf5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b8b64a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sum_of_numbers(number, numbers):\n",
    "    if number == (sum(numbers) - number):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4dede48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = df.groupby('adsh')['dta_min_accuracy'].unique().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a80e2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_sum_of_others = {}\n",
    "\n",
    "for k, v in temp_dict.items():\n",
    "    dta_sum_of_others[k] = max([is_sum_of_numbers(number = n, numbers = v) for n in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d4771cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_sum_of_others = pd.DataFrame(dta_sum_of_others, index = [0]).T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "255a22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta_sum_of_others.columns = ['adsh', 'dta_sum_of_others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c8fac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(right = dta_sum_of_others, how = 'left', on = 'adsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ca2f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dta_max'] = df.groupby('adsh')['value'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "927d2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['drop'] = np.where((df['dta_sum_of_others'] == True) &\n",
    "                      (df['value'] != df['dta_max']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0e8663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['drop'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a8c93d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['min_decimal', 'dta_min_accuracy', 'dta_max', 'dta_sum_of_others', 'drop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b44166b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3101ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = [('deferredtaxassetsgrossnoncurrent',\n",
    "           'deferredtaxassetsgrosscurrent')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53715941",
   "metadata": {},
   "outputs": [],
   "source": [
    "for combo in combos:\n",
    "    # identify reports that have the two tags AND ONLY the two tags\n",
    "    # otherwise I would drop companies that, e.g., only use\n",
    "    # 'deferredtaxassetsvaluationallowancenoncurrent' as their only tag to tag VAs\n",
    "    df['both_present'] = np.where((df['tag'] == combo[0]) |\n",
    "                                  (df['tag'] == combo[1]), 1, 0)\n",
    "    df['both_present'] = df.groupby('adsh')['both_present'].transform('sum')\n",
    "    df['total_tags'] = df.groupby('adsh')['tag'].transform('nunique')\n",
    "    save = df.loc[(df['both_present'] == 2) & (df['total_tags'] == 2)]\n",
    "    \n",
    "    # from va, drop unnecessary columns and drop those for which the tags will be summed up\n",
    "    df = df.drop(columns = ['both_present', 'total_tags'])\n",
    "    df = df.loc[~df['adsh'].isin(save['adsh'])]\n",
    "    \n",
    "    # sum up values and merge back info from 'save'\n",
    "    aggregated_values = save.groupby('adsh')['value'].sum().reset_index()\n",
    "    aggregated_values = aggregated_values.merge(right = save.drop_duplicates('adsh').drop(columns = ['both_present', 'total_tags', 'value']),\n",
    "                                                on = 'adsh', how = 'left')\n",
    "    # overwrite value of tag to be able to idenfity individually-calculated values later\n",
    "    aggregated_values['tag'] = 'CALCULATED_SUM'\n",
    "    \n",
    "    # concatenate va (from which the values that are summed up individually have been dropped above) and\n",
    "    # the individually-summed up values\n",
    "    df = pd.concat([df, aggregated_values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c9835",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3fa844a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all remaining duplicates\n",
    "df = df.drop_duplicates(subset = ['cik', 'fyear'], keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e5e87c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['adsh', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db3ce216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df['value'] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4361fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'value' : 'dta_gross'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c59fac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46275"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6aaaa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(os.getcwd(), '3_pipeline', '1_intermediate', 'dta_gross.tsv'),\n",
    "          sep = '\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
